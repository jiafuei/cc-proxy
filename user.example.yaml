# User configuration for cc-proxy
# Copy this file to ~/.cc-proxy/user.yaml and modify as needed

# Directory paths to search for external transformer modules
# These paths will be searched for custom transformer classes
transformer_paths:
  - '/path/to/custom/transformers'
  - '/another/transformer/directory'

providers:
  # Anthropic/Claude provider example
  # Handles requests to Anthropic's Claude API
  - name: 'anthropic-provider'
    api_key: !env ANTHROPIC_API_KEY  # Required: Your Anthropic API key from environment
    url: !env [ANTHROPIC_URL, 'https://api.anthropic.com/v1/messages']  # Optional: Custom URL with fallback
    timeout: !env [ANTHROPIC_TIMEOUT, 300]  # Request timeout in seconds
    transformers:
      request:
        # Optimizes cache breakpoints for Anthropic API (uses 4 max breakpoints)
        # - Removes cache from 'You are Claude' system message
        # - Adds cache to last system message and tools
        # - Adds cache breakpoints every 20 content blocks
        - class: 'app.services.transformers.anthropic.AnthropicCacheTransformer'
          params:
            max_tools_breakpoints: 1  # Maximum cache breakpoints for tools (default: 1)
        # Filters headers to include only Anthropic-compatible prefixes
        - class: 'app.services.transformers.anthropic.AnthropicHeadersTransformer'
          params: {}
        # Handles authentication headers for Anthropic API
        # API key is automatically taken from provider config
        - class: 'app.services.transformers.utils.AuthHeaderTransformer'
          params: {}  # Uses defaults: header_name='authorization', value_prefix='Bearer '
      response:
        # Passthrough transformer for Anthropic responses (no conversion needed)
        - class: 'app.services.transformers.anthropic.AnthropicResponseTransformer'
          params: {}

  # OpenAI provider example
  # Converts Claude API format to/from OpenAI API format
  - name: 'openai-provider'
    api_key: !env OPENAI_API_KEY  # Required: Your OpenAI API key from environment
    url: !env [OPENAI_URL, 'https://api.openai.com/v1/chat/completions']  # Optional: Custom URL with fallback
    timeout: !env [OPENAI_TIMEOUT, 300]
    transformers:
      request:
        # Generic auth header transformer (reusable across providers)
        - class: 'app.services.transformers.utils.AuthHeaderTransformer'
          params: {}  # Uses defaults: header_name='authorization', value_prefix='Bearer '
        # Converts Claude request format to OpenAI format
        # - Handles multimodal content (images, text)
        # - Converts tools and tool_choice
        # - Converts thinking budget to reasoning effort
        # - Handles system message conversion
        - class: 'app.services.transformers.openai.OpenAIRequestTransformer'
          params: {}  # API key and URL are taken from provider config
      response:
        # Converts OpenAI response format back to Claude format
        # - Handles both streaming and non-streaming responses
        # - Converts tool calls and tool results
        # - Maps OpenAI finish reasons to Claude stop reasons
        - class: 'app.services.transformers.openai.OpenAIResponseTransformer'
          params: {}

  # Custom provider with external transformers
  # Example of using custom transformer classes from transformer_paths
  - name: 'custom-provider'
    api_key: !env CUSTOM_API_KEY  # Required: Custom provider API key
    url: !env [CUSTOM_API_URL, 'https://custom-api.example.com/v1']  # Required: Custom API URL
    timeout: !env [CUSTOM_TIMEOUT, 300]
    transformers:
      request:
        - class: 'my_transformers.CustomAuthTransformer'
          params:
            api_key: !env CUSTOM_SPECIAL_KEY  # Alternative API key for special auth
            special_header: !env [CUSTOM_HEADER, 'value-1']  # Custom header value
      response:
        - class: 'my_transformers.CustomResponseTransformer'
          params:
            format_style: 'enhanced'

# Model definitions - link model IDs to providers
# Each model must reference a valid provider name
# Optional aliases provide short, memorable names for use in routing
models:
  # Anthropic/Claude models
  - id: 'claude-3-5-sonnet-20241022'
    provider: 'anthropic-provider'
    alias: 'sonnet'
  - id: 'claude-3-5-haiku-20241022'
    provider: 'anthropic-provider'
    alias: 'haiku'
  - id: 'claude-3-opus-20240229'
    provider: 'anthropic-provider'
    alias: 'opus'
  
  # OpenAI models
  - id: 'gpt-4o'
    provider: 'openai-provider'
    alias: 'gpt4'
  - id: 'gpt-4o-mini'
    provider: 'openai-provider'
    alias: 'gpt4-mini'
  - id: 'o1-preview'
    provider: 'openai-provider'
    alias: 'o1'
  - id: 'o1-mini'
    provider: 'openai-provider'
    alias: 'o1-mini'
  
  # Custom models
  - id: 'custom-model-1'
    provider: 'custom-provider'
    alias: 'custom1'
  - id: 'custom-model-2'
    provider: 'custom-provider'
    alias: 'custom2'

# Request routing configuration
# Routes different types of requests to appropriate models
# You can use either model IDs or aliases defined above
routing:
  default: !env [CC_PROXY_DEFAULT_MODEL, 'sonnet']        # Default model for requests
  background: !env [CC_PROXY_BACKGROUND_MODEL, 'haiku']   # flavor text, light summarization, topic detection etc
  planning: !env [CC_PROXY_PLANNING_MODEL, 'sonnet']      # Plan mode
  thinking: !env [CC_PROXY_THINKING_MODEL, 'sonnet']      # Whenever you add any of the phrases to your prompt: "think" < "think hard" < "think harder" < "ultrathink." Ref: https://www.anthropic.com/engineering/claude-code-best-practices
  plan_and_think: !env [CC_PROXY_PLAN_THINK_MODEL, 'sonnet']  # When thinking is activated in plan mode
